{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- ~~Create git repo~~\n",
    "- Neural Network Architecture to solve image colourization problem\n",
    "- Data Augmentation\n",
    "- Cross-validation\n",
    "- Testing a few optimizers\n",
    "- Testing various loss funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Training:   2%|‚ñè         | 3/185 [03:49<3:50:27, 75.98s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU is available and set PyTorch to use it\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, grayscale_dir, colorized_dir, transform=None):\n",
    "        self.grayscale_dir = grayscale_dir\n",
    "        self.colorized_dir = colorized_dir\n",
    "        self.grayscale_images = os.listdir(grayscale_dir)\n",
    "        self.colorized_images = os.listdir(colorized_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grayscale_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        grayscale_path = os.path.join(self.grayscale_dir, self.grayscale_images[idx])\n",
    "        colorized_path = os.path.join(self.colorized_dir, self.colorized_images[idx])\n",
    "        \n",
    "        grayscale_image = Image.open(grayscale_path).convert('L')\n",
    "        colorized_image = Image.open(colorized_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            grayscale_image = self.transform(grayscale_image)\n",
    "            colorized_image = self.transform(colorized_image)\n",
    "        \n",
    "        return grayscale_image, colorized_image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = ColorizationDataset('cv_p3_images_split/train/grayscale/', 'cv_p3_images_split/train/colored/', transform=transform)\n",
    "val_dataset = ColorizationDataset('cv_p3_images_split/validation/grayscale/', 'cv_p3_images_split/validation/colored/', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class ColorizationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = ColorizationNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for grayscale_images, colorized_images in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        grayscale_images = grayscale_images.to(device)\n",
    "        colorized_images = colorized_images.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(grayscale_images)\n",
    "        loss = criterion(outputs, colorized_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * grayscale_images.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for grayscale_images, colorized_images in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            grayscale_images = grayscale_images.to(device)\n",
    "            colorized_images = colorized_images.to(device)\n",
    "            \n",
    "            outputs = model(grayscale_images)\n",
    "            loss = criterion(outputs, colorized_images)\n",
    "            \n",
    "            val_loss += loss.item() * grayscale_images.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'colorization_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
