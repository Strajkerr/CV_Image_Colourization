{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/15\n",
      "\u001b[1m 74/300\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:27\u001b[0m 5s/step - accuracy: 0.4722 - loss: 0.0208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 1s/step - accuracy: 0.5077 - loss: 0.0156 - val_accuracy: 0.6516 - val_loss: 0.0649\n",
      "Epoch 2/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 1s/step - accuracy: 0.5549 - loss: 0.0108 - val_accuracy: 0.6507 - val_loss: 0.0588\n",
      "Epoch 3/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 1s/step - accuracy: 0.5572 - loss: 0.0102 - val_accuracy: 0.6515 - val_loss: 0.0547\n",
      "Epoch 4/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.5690 - loss: 0.0101 - val_accuracy: 0.6525 - val_loss: 0.0434\n",
      "Epoch 5/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.5707 - loss: 0.0096 - val_accuracy: 0.6529 - val_loss: 0.0345\n",
      "Epoch 6/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.5677 - loss: 0.0096 - val_accuracy: 0.6530 - val_loss: 0.0279\n",
      "Epoch 7/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.5708 - loss: 0.0096 - val_accuracy: 0.6508 - val_loss: 0.0170\n",
      "Epoch 8/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 1s/step - accuracy: 0.5691 - loss: 0.0093 - val_accuracy: 0.6500 - val_loss: 0.0136\n",
      "Epoch 9/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.5745 - loss: 0.0095 - val_accuracy: 0.5383 - val_loss: 0.0092\n",
      "Epoch 10/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.5799 - loss: 0.0094 - val_accuracy: 0.6138 - val_loss: 0.0084\n",
      "Epoch 11/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 1s/step - accuracy: 0.5797 - loss: 0.0089 - val_accuracy: 0.6345 - val_loss: 0.0083\n",
      "Epoch 12/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - accuracy: 0.5843 - loss: 0.0091 - val_accuracy: 0.6184 - val_loss: 0.0082\n",
      "Epoch 13/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - accuracy: 0.5781 - loss: 0.0090 - val_accuracy: 0.6119 - val_loss: 0.0082\n",
      "Epoch 14/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 1s/step - accuracy: 0.5834 - loss: 0.0090 - val_accuracy: 0.6442 - val_loss: 0.0085\n",
      "Epoch 15/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 1s/step - accuracy: 0.5879 - loss: 0.0086 - val_accuracy: 0.5932 - val_loss: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2/5\n",
      "Epoch 1/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 1s/step - accuracy: 0.5155 - loss: 0.0158 - val_accuracy: 0.6083 - val_loss: 0.0653\n",
      "Epoch 2/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - accuracy: 0.5663 - loss: 0.0107 - val_accuracy: 0.6084 - val_loss: 0.0586\n",
      "Epoch 3/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 1s/step - accuracy: 0.5741 - loss: 0.0104 - val_accuracy: 0.6057 - val_loss: 0.0534\n",
      "Epoch 4/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 1s/step - accuracy: 0.5735 - loss: 0.0103 - val_accuracy: 0.6022 - val_loss: 0.0425\n",
      "Epoch 5/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 1s/step - accuracy: 0.5896 - loss: 0.0103 - val_accuracy: 0.5998 - val_loss: 0.0362\n",
      "Epoch 6/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 1s/step - accuracy: 0.5734 - loss: 0.0097 - val_accuracy: 0.6075 - val_loss: 0.0273\n",
      "Epoch 7/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 1s/step - accuracy: 0.5856 - loss: 0.0098 - val_accuracy: 0.6087 - val_loss: 0.0152\n",
      "Epoch 8/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 1s/step - accuracy: 0.5880 - loss: 0.0095 - val_accuracy: 0.5751 - val_loss: 0.0103\n",
      "Epoch 9/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 1s/step - accuracy: 0.5837 - loss: 0.0094 - val_accuracy: 0.5944 - val_loss: 0.0138\n",
      "Epoch 10/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 1s/step - accuracy: 0.5852 - loss: 0.0097 - val_accuracy: 0.5914 - val_loss: 0.0078\n",
      "Epoch 11/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 1s/step - accuracy: 0.5887 - loss: 0.0093 - val_accuracy: 0.5783 - val_loss: 0.0078\n",
      "Epoch 12/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 1s/step - accuracy: 0.5901 - loss: 0.0092 - val_accuracy: 0.5491 - val_loss: 0.0076\n",
      "Epoch 13/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.5929 - loss: 0.0092 - val_accuracy: 0.5437 - val_loss: 0.0075\n",
      "Epoch 14/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5906 - loss: 0.0093 - val_accuracy: 0.5428 - val_loss: 0.0076\n",
      "Epoch 15/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.5864 - loss: 0.0091 - val_accuracy: 0.5527 - val_loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3/5\n",
      "Epoch 1/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.5048 - loss: 0.0167 - val_accuracy: 0.6333 - val_loss: 0.0657\n",
      "Epoch 2/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5552 - loss: 0.0107 - val_accuracy: 0.6333 - val_loss: 0.0614\n",
      "Epoch 3/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 0.0105 - val_accuracy: 0.6333 - val_loss: 0.0519\n",
      "Epoch 4/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5778 - loss: 0.0099 - val_accuracy: 0.6333 - val_loss: 0.0440\n",
      "Epoch 5/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 1s/step - accuracy: 0.5805 - loss: 0.0100 - val_accuracy: 0.6336 - val_loss: 0.0373\n",
      "Epoch 6/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5804 - loss: 0.0096 - val_accuracy: 0.6319 - val_loss: 0.0257\n",
      "Epoch 7/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5755 - loss: 0.0096 - val_accuracy: 0.6296 - val_loss: 0.0154\n",
      "Epoch 8/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 1s/step - accuracy: 0.5821 - loss: 0.0097 - val_accuracy: 0.6183 - val_loss: 0.0128\n",
      "Epoch 9/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.5767 - loss: 0.0091 - val_accuracy: 0.6241 - val_loss: 0.0093\n",
      "Epoch 10/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.5845 - loss: 0.0089 - val_accuracy: 0.6255 - val_loss: 0.0083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4/5\n",
      "Epoch 1/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 1s/step - accuracy: 0.5253 - loss: 0.0156 - val_accuracy: 0.6120 - val_loss: 0.0642\n",
      "Epoch 2/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5584 - loss: 0.0108 - val_accuracy: 0.6095 - val_loss: 0.0566\n",
      "Epoch 3/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.5763 - loss: 0.0107 - val_accuracy: 0.6136 - val_loss: 0.0494\n",
      "Epoch 4/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 1s/step - accuracy: 0.5799 - loss: 0.0102 - val_accuracy: 0.6136 - val_loss: 0.0434\n",
      "Epoch 5/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 1s/step - accuracy: 0.5801 - loss: 0.0100 - val_accuracy: 0.6136 - val_loss: 0.0329\n",
      "Epoch 6/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 1s/step - accuracy: 0.5891 - loss: 0.0100 - val_accuracy: 0.6138 - val_loss: 0.0227\n",
      "Epoch 7/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5788 - loss: 0.0095 - val_accuracy: 0.6139 - val_loss: 0.0175\n",
      "Epoch 8/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5842 - loss: 0.0097 - val_accuracy: 0.6131 - val_loss: 0.0122\n",
      "Epoch 9/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5926 - loss: 0.0095 - val_accuracy: 0.5999 - val_loss: 0.0102\n",
      "Epoch 10/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5864 - loss: 0.0091 - val_accuracy: 0.6034 - val_loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5/5\n",
      "Epoch 1/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 1s/step - accuracy: 0.5027 - loss: 0.0161 - val_accuracy: 0.6215 - val_loss: 0.0653\n",
      "Epoch 2/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5455 - loss: 0.0108 - val_accuracy: 0.6231 - val_loss: 0.0613\n",
      "Epoch 3/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5655 - loss: 0.0104 - val_accuracy: 0.6236 - val_loss: 0.0518\n",
      "Epoch 4/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.5686 - loss: 0.0097 - val_accuracy: 0.6233 - val_loss: 0.0437\n",
      "Epoch 5/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5721 - loss: 0.0097 - val_accuracy: 0.6191 - val_loss: 0.0349\n",
      "Epoch 6/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.5749 - loss: 0.0098 - val_accuracy: 0.6111 - val_loss: 0.0245\n",
      "Epoch 7/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 1s/step - accuracy: 0.5780 - loss: 0.0095 - val_accuracy: 0.6225 - val_loss: 0.0190\n",
      "Epoch 8/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5859 - loss: 0.0093 - val_accuracy: 0.6031 - val_loss: 0.0117\n",
      "Epoch 9/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 1s/step - accuracy: 0.5855 - loss: 0.0092 - val_accuracy: 0.6169 - val_loss: 0.0090\n",
      "Epoch 10/15\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 1s/step - accuracy: 0.5881 - loss: 0.0092 - val_accuracy: 0.5726 - val_loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.saving import register_keras_serializable\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Register custom functions (loss functions in this case)\n",
    "@register_keras_serializable()\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "@register_keras_serializable()\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "# Define paths to your dataset\n",
    "data_dir = \"..//cv_p3_images_split\"\n",
    "train_gray_dir = os.path.join(data_dir, \"train/grayscale\")\n",
    "train_color_dir = os.path.join(data_dir, \"train/colored\")\n",
    "val_gray_dir = os.path.join(data_dir, \"validation/grayscale\")\n",
    "val_color_dir = os.path.join(data_dir, \"validation/colored\")\n",
    "\n",
    "# Image dimensions for resizing\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256  # Resize all images to 256x256\n",
    "\n",
    "# Utility function to preprocess images (loading and resizing)\n",
    "def preprocess_image(image_path, target_size):\n",
    "    image = load_img(image_path, target_size=target_size, color_mode=\"rgb\")\n",
    "    image = img_to_array(image) / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "# Function to load a dataset from a folder (grayscale and color images)\n",
    "def load_dataset(gray_folder, color_folder, target_size, fraction=1.0):\n",
    "    gray_images = []\n",
    "    color_images = []\n",
    "    \n",
    "    filenames = os.listdir(gray_folder)\n",
    "    if fraction < 1.0:\n",
    "        filenames = random.sample(filenames, int(len(filenames) * fraction))  # Sample fraction of filenames\n",
    "    \n",
    "    for filename in filenames:\n",
    "        gray_path = os.path.join(gray_folder, filename)\n",
    "        color_path = os.path.join(color_folder, filename)\n",
    "        gray_images.append(preprocess_image(gray_path, target_size)[..., 0:1])  # Extract grayscale channel\n",
    "        color_images.append(preprocess_image(color_path, target_size))\n",
    "    \n",
    "    return np.array(gray_images), np.array(color_images)\n",
    "\n",
    "# Load train and validation datasets\n",
    "train_gray, train_color = load_dataset(train_gray_dir, train_color_dir, (IMG_HEIGHT, IMG_WIDTH), 0.25)\n",
    "val_gray, val_color = load_dataset(val_gray_dir, val_color_dir, (IMG_HEIGHT, IMG_WIDTH), 0.25)\n",
    "\n",
    "# Define the colorization model architecture\n",
    "def build_model():\n",
    "    inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\", strides=1)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\", strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding=\"same\", strides=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Decoder with skip connections\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # Final layer\n",
    "    x = Conv2D(3, (3, 3), padding=\"same\")(x)\n",
    "    outputs = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# Define cross-validation setup with KFold (5 folds)\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Create an EarlyStopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Perform cross-validation and train the model\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_gray)):\n",
    "    print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "    # Split the data into training and validation for this fold\n",
    "    fold_train_gray, fold_val_gray = train_gray[train_index], train_gray[val_index]\n",
    "    fold_train_color, fold_val_color = train_color[train_index], train_color[val_index]\n",
    "\n",
    "    # Build and compile the model\n",
    "    model = build_model()\n",
    "    \n",
    "    # Compile the model using RMSProp optimizer\n",
    "    model.compile(\n",
    "        optimizer=RMSprop(learning_rate=0.001),  # RMSProp optimizer with learning rate 0.001\n",
    "        loss=\"mse\",  # Mean squared error loss function\n",
    "        metrics=['accuracy']  # You can add other metrics if needed\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        fold_train_gray, fold_train_color,\n",
    "        validation_data=(fold_val_gray, fold_val_color),\n",
    "        epochs=15,\n",
    "        steps_per_epoch=300,\n",
    "        batch_size=16,\n",
    "        callbacks=[early_stopping]  # Use early stopping to prevent overfitting\n",
    "    )\n",
    "\n",
    "    # Save the model after training\n",
    "    model.save(f'colorization_model_fold_{fold + 1}.h5')\n",
    "\n",
    "    # Optionally, you can save the training history and plot results\n",
    "    # Save the training and validation loss plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss - Fold {fold + 1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'..//raport_sources/training_validation_loss_fold_{fold + 1}.png')  # Save plot\n",
    "    plt.close()\n",
    "\n",
    "    # Optionally, you can save predictions for further analysis\n",
    "    # predictions = model.predict(fold_val_gray)\n",
    "    # Save or process the predictions as required.\n",
    "\n",
    "print(\"Cross-validation completed.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
