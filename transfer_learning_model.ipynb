{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 13.3 GiB for an array with shape (23648, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(gray_images), np\u001b[38;5;241m.\u001b[39marray(color_images)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Load train and validation data\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m train_gray, train_color \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_GRAY_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_COLOR_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m val_gray, val_color \u001b[38;5;241m=\u001b[39m load_data(VAL_GRAY_DIR, VAL_COLOR_DIR)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_colorization_model\u001b[39m():\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Grayscale input\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [3], line 47\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(gray_dir, color_dir)\u001b[0m\n\u001b[0;32m     44\u001b[0m     gray_images\u001b[38;5;241m.\u001b[39mappend(preprocess_image(gray_path, is_grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     45\u001b[0m     color_images\u001b[38;5;241m.\u001b[39mappend(preprocess_image(color_path))\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(gray_images), \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor_images\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.3 GiB for an array with shape (23648, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "# Constants\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224  # Input dimensions for ResNet50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Paths to datasets\n",
    "DATA_DIR = \"cv_p3_images_split\"\n",
    "TRAIN_GRAY_DIR = os.path.join(DATA_DIR, \"train/grayscale\")\n",
    "TRAIN_COLOR_DIR = os.path.join(DATA_DIR, \"train/colored\")\n",
    "VAL_GRAY_DIR = os.path.join(DATA_DIR, \"validation/grayscale\")\n",
    "VAL_COLOR_DIR = os.path.join(DATA_DIR, \"validation/colored\")\n",
    "TEST_GRAY_DIR = os.path.join(DATA_DIR, \"test/grayscale\")\n",
    "TEST_COLOR_DIR = os.path.join(DATA_DIR, \"test/colored\")\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def preprocess_image(image_path, target_size=(IMG_HEIGHT, IMG_WIDTH), is_grayscale=False):\n",
    "    img = load_img(image_path, target_size=target_size, color_mode=\"grayscale\" if is_grayscale else \"rgb\")\n",
    "    img = img_to_array(img)\n",
    "    if is_grayscale:\n",
    "        img = img / 255.0  # Normalize grayscale images\n",
    "    else:\n",
    "        img = img / 255.0  # Normalize RGB images\n",
    "    return img\n",
    "\n",
    "# Load dataset\n",
    "def load_data(gray_dir, color_dir):\n",
    "    gray_images = []\n",
    "    color_images = []\n",
    "\n",
    "    for filename in os.listdir(gray_dir):\n",
    "        gray_path = os.path.join(gray_dir, filename)\n",
    "        color_path = os.path.join(color_dir, filename)\n",
    "        \n",
    "        gray_images.append(preprocess_image(gray_path, is_grayscale=True))\n",
    "        color_images.append(preprocess_image(color_path))\n",
    "\n",
    "    return np.array(gray_images), np.array(color_images)\n",
    "\n",
    "# Load train and validation data\n",
    "train_gray, train_color = load_data(TRAIN_GRAY_DIR, TRAIN_COLOR_DIR)\n",
    "val_gray, val_color = load_data(VAL_GRAY_DIR, VAL_COLOR_DIR)\n",
    "\n",
    "def build_colorization_model():\n",
    "    # Grayscale input\n",
    "    input_layer = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "    \n",
    "    # Convert grayscale to 3 channels for pretrained model compatibility\n",
    "    x = Conv2D(3, (3, 3), padding=\"same\", activation=\"relu\")(input_layer)\n",
    "    \n",
    "    # Pretrained ResNet50 as the base model\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    base_model.trainable = False  # Freeze base model initially\n",
    "    x = base_model(x)\n",
    "\n",
    "    # Add upsampling layers to restore dimensions to (224, 224, 3)\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (56, 56, channels)\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (112, 112, channels)\n",
    "    x = UpSampling2D((2, 2))(x)  # Upsample to (224, 224, channels)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)  # Final output layer\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "\n",
    "# Build and compile model\n",
    "model = build_colorization_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Training\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    train_gray,\n",
    "    train_color,\n",
    "    validation_data=(val_gray, val_color),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_gray, test_color = load_data(TEST_GRAY_DIR, TEST_COLOR_DIR)\n",
    "loss, accuracy = model.evaluate(test_gray, test_color)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Visualize Predictions\n",
    "def visualize_predictions(model, gray_images, color_images, num_samples=5):\n",
    "    predictions = model.predict(gray_images[:num_samples])\n",
    "    for i in range(num_samples):\n",
    "        predicted_img = array_to_img(predictions[i])\n",
    "        gray_img = array_to_img(gray_images[i])\n",
    "        true_color_img = array_to_img(color_images[i])\n",
    "\n",
    "        print(\"Sample\", i + 1)\n",
    "        predicted_img.show(title=\"Predicted Image\")\n",
    "        gray_img.show(title=\"Grayscale Image\")\n",
    "        true_color_img.show(title=\"Ground Truth\")\n",
    "\n",
    "visualize_predictions(model, test_gray, test_color, num_samples=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
