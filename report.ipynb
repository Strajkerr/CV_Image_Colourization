{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Project 3 - Image Colourization on pets dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared by:\n",
    " - Marianna Myszkowska 156041\n",
    " - Jakub Liszy≈Ñski 156060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set\n",
    "The Oxford-IIIT Pet Dataset is a comprehensive collection of images featuring 37 distinct pet breeds, including both cats and dogs, with approximately 200 images per breed. The dataset offers significant diversity in terms of scale, pose, and lighting conditions, making it valuable for various computer vision tasks.\n",
    "\n",
    "### Key Features:\n",
    "- **Breed Annotations:** Each image is labeled with its respective breed, facilitating classification tasks.\n",
    "- **Head Region of Interest (ROI):** Annotations include bounding boxes around the pet's head, aiding in localization studies.\n",
    "- **Pixel-Level Trimap Segmentation:** Detailed annotations provide pixel-wise segmentation, distinguishing between the pet, foreground, and background, which is particularly useful for segmentation tasks.\n",
    "\n",
    "## Sample Images:\n",
    "Here are a few examples from the dataset:\n",
    "\n",
    "\n",
    "![card](dataset-card.png) \n",
    "\n",
    "\n",
    "In order to use this dataset for our project we wil first convert images to grayscale and only then we wil use them. The Original images will be used as a reference while coloring the images.\n",
    "\n",
    "![colored](cv_p3_images\\Abyssinian_1.jpg) \n",
    "![gray](cv_p3_images\\gray\\Abyssinian_1_gray.jpg) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "def convert_images_to_grayscale(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            gray_img_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_gray{os.path.splitext(filename)[1]}\")\n",
    "            img.save(gray_img_path)\n",
    "            print(f\"Converted {filename} to grayscale and saved as {gray_img_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For more information and to access the dataset, please visit the [official website](https://www.robots.ox.ac.uk/~vgg/data/pets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem - Image colorization\n",
    "Image colorization is the process of adding plausible color information to grayscale images or videos. This task is inherently challenging due to its ill-posed nature; a single grayscale image can correspond to multiple valid color interpretations. Consequently, the model must infer and predict realistic colors for each pixel, often relying on learned patterns and contextual cues. \n",
    "\n",
    "Traditionally, colorization was performed manually by artists, which was time-consuming and required significant expertise. With advancements in deep learning, automated approaches have been developed to tackle this problem. These methods typically involve training convolutional neural networks (CNNs) on large datasets of color images. During training, the models learn to map grayscale inputs to their corresponding color outputs, capturing semantic and contextual information to produce realistic colorizations.\n",
    "\n",
    "Despite these advancements, challenges remain. The ambiguity of the task means that multiple color outputs can be correct for a single grayscale input. For instance, a grayscale image of a car could be red, blue, or any other color, and all would be plausible. Addressing this uncertainty is a key focus in current research, with approaches exploring probabilistic models and user-guided colorization to refine results. \n",
    "\n",
    "In summary, image colorization is a complex and underdetermined problem that seeks to enrich grayscale images by predicting and applying appropriate colors, leveraging machine learning techniques to achieve this goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used architectures\n",
    "description of used architectures with diagram showing the layers; For large models containing blocks, the blocks and the connections between them can be shown separately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis\n",
    "model analysis: size in memory, number of parameters,  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "description of the training and the required commands to run it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "description of used metrics, loss, and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "plots: training and validation loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "used hyperparameters along with an explanation of each why such value was chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "comparison of models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "list of libraries and tools used can be a requirements.txt file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rutime enviroment\n",
    "a description of the runtime environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography \n",
    "preparation of a bibliography - the bibliography should contain references to the data set (preferably the article in which the collection was presented) and all scientific works and studies, including websites with tips on the solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points\n",
    "| **Task**                                         | **Status**      | **Points** |\n",
    "|--------------------------------------------------|-----------------|------------|\n",
    "| **Problem: Colorization**                        |  In progress    | 1          |\n",
    "| **Model: Pre-trained model (different problem)** |  In progress    | 1          |\n",
    "| **Data Augmentation**                            |  In progress    | 1          |\n",
    "| **Cross-Validation**                             |  Not Attempted  | 1          |\n",
    "| **Testing Optimizers (at least 3)**              |  Not Attempted  | 1          |\n",
    "| **Testing Loss Functions (at least 3)**          |  Not Attempted  | 1          |\n",
    "| **Dataset Requirements (at least 1000 images)**  |  Completed      | 0 (default requirement) |\n",
    "| **Metrics (at least 2)**                         |  Not Attempted  | 0 (default requirement) |\n",
    "| **Report (descriptions, diagrams, etc.)**        |  In progress    | 0          |\n",
    "| **Visualization Tools (e.g., TensorBoard)**      |  Not Attempted  | 1          |\n",
    "\n",
    "### **Points Summary**\n",
    "- **Problem**: 1 \n",
    "- **Model**: 1 \n",
    "- **Additional Points (Training, Dataset, Tools)**: 5 \n",
    "- **Total Points**: **7**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[Link to Git](https://github.com/Strajkerr/CV_Image_Colourization)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
